{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch \n",
    "import matplotlib.pyplot as plt\n",
    "import enum\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "import cv2 #pip install opencv-python\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.image as mpimg\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.models import resnet50\n",
    "from torchvision import datasets, models, transforms\n",
    "import torchvision\n",
    "import copy\n",
    "import sklearn.metrics\n",
    "import time\n",
    "import torch.utils\n",
    "import torch.utils.data\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run preprocess.ipynb\n",
    "%run stinna.ipynb\n",
    "%run extraFunctions.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data into train set, validation set and test set with ratio 80/10/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import splitfolders\n",
    "# splitfolders.ratio(PATHbirdsWithBackground, output=\"output\",seed=42, ratio=(0.8,0.1,0.1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TEST = \"split_withbackground/test\"\n",
    "PATH_TRAIN = \"split_withbackground/train\"\n",
    "PATH_VAL = \"split_withbackground/val\"\n",
    "PATH_FEEDER = \"feeder-data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ResNet accepts input images of shape `(3 x 224 x 224)` and they must be loaded in to a range of `[0,1]` and normalised using `mean = [0.485, 0.456, 0.406]` and `std = [0.229, 0.224, 0.225]` (https://pytorch.org/hub/pytorch_vision_resnet/). Our data already has the correct size, so here, we simply add `ToTensor()`, which converts the images from `(H x W x C)` in range `[0,255]` to `(C x H x W)` in range `[0.0,1.0]`, and the normalisation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datasets from our imagefolders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test = datasets.ImageFolder(PATH_TEST, preprocess_transforms)\n",
    "dataset_train = datasets.ImageFolder(PATH_TRAIN, preprocess_transforms)\n",
    "dataset_val = datasets.ImageFolder(PATH_VAL, preprocess_transforms)\n",
    "dataset_feeder = datasets.ImageFolder(PATH_FEEDER, preprocess_transforms)\n",
    "\n",
    "dataset_size_train = len(dataset_train)\n",
    "dataset_size_val = len(dataset_val)\n",
    "\n",
    "# print('No of images in training set: {}'.format(len(dataset_train)))\n",
    "# print('No of images in validation set: {}'.format(len(dataset_val)))\n",
    "# print('No of images in test set: {}'.format(len(dataset_test)))\n",
    "# print('No of images in feeder set: {}'.format(len(dataset_feeder)))\n",
    "\n",
    "class_labels = dataset_val.classes\n",
    "# print('Labels: {}'.format(class_labels))\n",
    "# print('Labels (feeder): {}'.format(dataset_feeder.classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataLOADERS (which is what we feed to the training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_train = torch.utils.data.DataLoader(dataset_train, batch_size=4, shuffle=True, num_workers=4)\n",
    "dataloader_validation = torch.utils.data.DataLoader(dataset_val, batch_size=4, shuffle=True, num_workers=4)\n",
    "dataloader_test = torch.utils.data.DataLoader(dataset_test, batch_size=4, shuffle=False, num_workers=4)\n",
    "dataloader_feeder = torch.utils.data.DataLoader(dataset_feeder, batch_size=4, shuffle=False, num_workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x153df0f40>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/athallenberg/miniconda3/envs/dm/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/Users/athallenberg/miniconda3/envs/dm/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1443, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/Users/athallenberg/miniconda3/envs/dm/lib/python3.11/multiprocessing/process.py\", line 149, in join\n",
      "    res = self._popen.wait(timeout)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/athallenberg/miniconda3/envs/dm/lib/python3.11/multiprocessing/popen_fork.py\", line 40, in wait\n",
      "    if not wait([self.sentinel], timeout):\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/athallenberg/miniconda3/envs/dm/lib/python3.11/multiprocessing/connection.py\", line 948, in wait\n",
      "    ready = selector.select(timeout)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/athallenberg/miniconda3/envs/dm/lib/python3.11/selectors.py\", line 415, in select\n",
      "    fd_event_list = self._selector.poll(timeout)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt: \n"
     ]
    }
   ],
   "source": [
    "# for taking a little look at the data :) \n",
    "# inputs, classes = next(iter(dataloader_train))\n",
    "# out = torchvision.utils.make_grid(inputs)\n",
    "# imshow(out, title=[class_labels[x] for x in classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting a subset to be able to test our code before doing big boi training\n",
    "subset1 = torch.utils.data.Subset(dataset_train, np.random.choice(len(dataset_train), 16, replace=False))\n",
    "subset2 = torch.utils.data.Subset(dataset_val, [1,8,9,16, 60, 80, 98, 100, 103, 20,31, 40,50,70,90,88])\n",
    "dataloader_tiny = DataLoader(subset1, batch_size=4, shuffle=True, num_workers=0)\n",
    "dataloader_tiny_val = DataLoader(subset2, batch_size=4, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing ResNet50 model \n",
    "and getting it ready for transfer learning!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put the pedal to the metal and use GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_weights = models.ResNet50_Weights.DEFAULT\n",
    "def load_and_prep_resnet50(weights = pretrained_weights):\n",
    "    model = torchvision.models.resnet50(weights=weights)\n",
    "    \n",
    "    #Replace last layer to match our 7 classes\n",
    "    model.fc = torch.nn.Linear(model.fc.in_features, 7)\n",
    "\n",
    "    # Freeze all layers (i.e., disable training so we dont start from scratch)\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    # Unfreeze final layer (named fc) s.t. we only train that to get a better starting point for fine tuning\n",
    "    for param in model.fc.parameters():\n",
    "        param.requires_grad = True\n",
    "    \n",
    "    # Put the model on the GPU\n",
    "    model = model.to(device)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def unfreeze_layers(model):\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "def unfreeze_layer4(model: torchvision.models.resnet50):\n",
    "    model.layer4.requires_grad_ = True    \n",
    "\n",
    "def get_optimizer(model):\n",
    "    #Use stochastic gradient descent and optimize parameters\n",
    "    return torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, optimizer, num_epoch=5, train = dataloader_train, validation= dataloader_validation):\n",
    "    acc_train = []\n",
    "    loss_train = []\n",
    "    acc_validation = []\n",
    "    loss_validation = []\n",
    "    best_acc = 0.0\n",
    "    best_loss = 1.0\n",
    "    best_epoch = 0\n",
    "    best_model_weight = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    since = time.time()\n",
    "    for epoch in range(num_epoch):\n",
    "        epoch_since = time.time()\n",
    "        print('Epoch {}/{}'.format(epoch+1, num_epoch))\n",
    "        print(\"-\"*10)\n",
    "        #training phase\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "        for inputs, labels in train:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            #zero the parameter gradients \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            #forward\n",
    "            with torch.set_grad_enabled(True):\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                criterion = torch.nn.CrossEntropyLoss()\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "        epoch_loss_train = running_loss / dataset_size_train\n",
    "        epoch_acc_train = running_corrects.double() / dataset_size_train\n",
    "        acc_train.append(epoch_acc_train.item())\n",
    "        loss_train.append(epoch_loss_train)\n",
    "        print('Train Loss: {:.4f} Acc: {:.4f}'.format(epoch_loss_train, epoch_acc_train))\n",
    "\n",
    "        #validation phase\n",
    "        model.eval()\n",
    "        running_loss_val = 0.0\n",
    "        running_corrects_val = 0\n",
    "        for inputs, labels in validation:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            with torch.set_grad_enabled(False):\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                criterion = torch.nn.CrossEntropyLoss()\n",
    "                loss = criterion(outputs, labels)\n",
    "            running_loss_val += loss.item() * inputs.size(0)\n",
    "            running_corrects_val += torch.sum(preds == labels.data)\n",
    "        epoch_loss_val = running_loss_val / dataset_size_val\n",
    "        epoch_acc_val = running_corrects_val.double() / dataset_size_val\n",
    "        acc_validation.append(epoch_acc_val.item())\n",
    "        loss_validation.append(epoch_loss_val)\n",
    "        print('Val Loss: {:.4f} Acc: {:.4f}'.format(epoch_loss_val, epoch_acc_val))\n",
    "        \n",
    "        if(epoch_acc_val > best_acc):\n",
    "            best_acc = epoch_acc_val\n",
    "            best_loss = epoch_loss_val #not ness the best loss overall but the loss of the best model\n",
    "            best_epoch = epoch+1\n",
    "            best_model_weight = copy.deepcopy(model.state_dict())\n",
    "        \n",
    "        time_epoch_val = time.time() - epoch_since           \n",
    "        print('Epoch time {:.0f}m {:.0f}s'.format(time_epoch_val // 60, time_epoch_val % 60))\n",
    "        print(\"-\"*10)\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print(\"Validation accuracies:\")\n",
    "    print(acc_validation)\n",
    "    print(\"Training accuracies:\")\n",
    "    print(acc_train)\n",
    "    print(\"Best model had accuracy {:.4f}, loss {:.4f} at epoch {}\".format(best_acc, best_loss, best_epoch))\n",
    "    data = {\"train_loss\": loss_train, \"val_loss\": loss_validation, \"train_acc\": acc_train, \"val_acc\": acc_validation, \"epochs\": num_epoch, \"batch_size\": train.batch_size}\n",
    "    model.load_state_dict(best_model_weight)\n",
    "    return model, data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_stats(data: dict):\n",
    "    print(\"Training accuracies\")\n",
    "    print(data[\"train_acc\"])\n",
    "    print(\"Validation Accuracies\")\n",
    "    print(data[\"val_acc\"])\n",
    "    print(\"Validation Loss\")\n",
    "    print(data[\"val_loss\"])\n",
    "    print(\"Lowest loss was {:.4f} at epoch {}\".format(np.min(data[\"val_loss\"]), np.argmin(data[\"val_loss\"])+1))\n",
    "    print(\"Highest accuracy was {:.4f} at epoch {}\".format(np.max(data[\"val_acc\"]),np.argmax(data[\"val_acc\"])+1))\n",
    "    if (\"epochs\" in data):\n",
    "        print(\"Number of epochs run \", data[\"epochs\"])\n",
    "    if(\"batch_size\" in data):\n",
    "        print(\"Batch size was \", data[\"batch_size\"])\n",
    "    if(\"optimizer\" in data):\n",
    "        print(\"Optimizer used: \", data[\"optimizer\"])\n",
    "    if(\"test_acc\" in data):\n",
    "        print(\"Overall accuracy on test data {:.4f}\".format(data[\"test_acc\"]))\n",
    "    if(\"feeder_acc\" in data):\n",
    "        print(\"Overall accuracy on feeder data {:.4f}\".format(data[\"feeder_acc\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_function(model_path: str, model_key: str = \"model\", info_key: str = \"info\"):\n",
    "    ''' \n",
    "    e.g. model, info = load_function(\"Cycle.tar\", model_key=\"model_cycle\", info_key = \"model_cycle_data\")  \n",
    "    or model, info = load_function(\"Cycle.tar\") if saved under model and info '''\n",
    "    loaded_info = torch.load(model_path, weights_only=True)\n",
    "    new_model = load_and_prep_resnet50()\n",
    "    new_model.load_state_dict(loaded_info[model_key])\n",
    "    info = loaded_info[info_key]\n",
    "    return new_model, info \n",
    "\n",
    "def save_function(model_path: str, model, info:dict, extra_info:dict):\n",
    "    ''' e.g. save_function(\"model_aug.tar\", model, info, extra={\"optimizer\": \"Adam\", \"test_acc\" 0.97, \"feeder_acc\": 0.38})'''\n",
    "    all_info = {}\n",
    "    all_info.update(info)\n",
    "    all_info.update(extra_info)\n",
    "    torch.save({\"model\": model.state_dict(), \"info\": all_info}, model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
