{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not strictly necessary, but imported anyway for the IDE haha\n",
    "import torch\n",
    "from torchvision import datasets, transforms \n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "%run setup.ipynb "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change model setup \n",
    "\n",
    "Change learning rate and add weight decay "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the transforms including augmentations (and also the basic ToTensor and normalisation)\n",
    "preprocess_with_augmentation = transforms.Compose([\n",
    "    transforms.ColorJitter(brightness=0.1),\n",
    "    transforms.GaussianBlur(kernel_size=(5,5), sigma=(7, 9)),\n",
    "    transforms.RandomRotation(degrees=10),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomResizedCrop(size=224,scale=(0.3,1)), # lowerbound the scale at 30 % of og img to not get too small portions\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Datasets and loaders with augmentations added \n",
    "dataset_train_aug = datasets.ImageFolder(PATH_TRAIN, preprocess_with_augmentation)\n",
    "dataloader_train_aug = torch.utils.data.DataLoader(dataset_train_aug, batch_size=8, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set and load model\n",
    "untrained_model_aug = load_and_prep_resnet50()\n",
    "optimizer = torch.optim.SGD(untrained_model_aug.parameters(), lr=0.02, momentum=0.9, weight_decay=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freezetrained_model_aug, _ = train_model(model=untrained_model_aug, optimizer=optimizer, num_epoch=24, train=dataloader_train_aug) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unfreeze_layers(freezetrained_model_aug)\n",
    "model_aug, model_aug_info = train_model(model=freezetrained_model_aug, optimizer=optimizer, num_epoch=24, train=dataloader_train_aug)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_model(model_aug, dataloader_tiny_val, class_labels, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_accuracies(model_aug_info[\"train_loss\"], model_aug_info[\"val_loss\"], [\"Train\", \"Val\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_accuracies(model_aug_info[\"train_acc\"], model_aug_info[\"val_acc\"], [\"Train\", \"Val\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truel, predl = makeAll(dataloader_test, model_aug, device)\n",
    "plot_confusion_matrix(truel, predl, class_labels, normalize=True)\n",
    "print(\"Accuracy\", (np.sum(predl==truel)/predl.size * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = ['blueTit', 'chaffinch', 'coalTit', 'goldfinch', 'greatTit', 'robin', 'starling']\n",
    "print(classification_report(truel, predl, target_names=class_labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
