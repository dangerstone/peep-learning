{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch \n",
    "import matplotlib.pyplot as plt\n",
    "import enum\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "import cv2 #pip install opencv-python\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.image as mpimg\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.models import resnet50\n",
    "from torchvision import datasets, models, transforms\n",
    "import torchvision\n",
    "import copy\n",
    "import sklearn.metrics\n",
    "import time\n",
    "import torch.utils\n",
    "import torch.utils.data\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run preprocess.ipynb\n",
    "%run stinna.ipynb\n",
    "%run extraFunctions.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data into train set, validation set and test set with ratio 80/10/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import splitfolders\n",
    "# splitfolders.ratio(PATHbirdsWithBackground, output=\"output\",seed=42, ratio=(0.8,0.1,0.1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TEST = \"split_withbackground/test\"\n",
    "PATH_TRAIN = \"split_withbackground/train\"\n",
    "PATH_VAL = \"split_withbackground/val\"\n",
    "PATH_FEEDER = \"feeder-data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ResNet accepts input images of shape `(3 x 224 x 224)` and they must be loaded in to a range of `[0,1]` and normalised using `mean = [0.485, 0.456, 0.406]` and `std = [0.229, 0.224, 0.225]` (https://pytorch.org/hub/pytorch_vision_resnet/). Our data already has the correct size, so here, we simply add `ToTensor()`, which converts the images from `(H x W x C)` in range `[0,255]` to `(C x H x W)` in range `[0.0,1.0]`, and the normalisation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datasets from our imagefolders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of images in training set: 835\n",
      "No of images in validation set: 104\n",
      "No of images in test set: 105\n",
      "No of images in feeder set: 15079\n"
     ]
    }
   ],
   "source": [
    "dataset_test = datasets.ImageFolder(PATH_TEST, preprocess_transforms)\n",
    "dataset_train = datasets.ImageFolder(PATH_TRAIN, preprocess_transforms)\n",
    "dataset_val = datasets.ImageFolder(PATH_VAL, preprocess_transforms)\n",
    "dataset_feeder = datasets.ImageFolder(PATH_FEEDER, preprocess_transforms)\n",
    "\n",
    "dataset_size_train = len(dataset_train)\n",
    "dataset_size_val = len(dataset_val)\n",
    "\n",
    "print('No of images in training set: {}'.format(len(dataset_train)))\n",
    "print('No of images in validation set: {}'.format(len(dataset_val)))\n",
    "print('No of images in test set: {}'.format(len(dataset_test)))\n",
    "print('No of images in feeder set: {}'.format(len(dataset_feeder)))\n",
    "\n",
    "class_labels = dataset_val.classes\n",
    "# print('Labels: {}'.format(class_labels))\n",
    "# print('Labels (feeder): {}'.format(dataset_feeder.classes))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataLOADERS (which is what we feed to the training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_train = torch.utils.data.DataLoader(dataset_train, batch_size=16, shuffle=True, num_workers=4)\n",
    "dataloader_validation = torch.utils.data.DataLoader(dataset_val, batch_size=16, shuffle=True, num_workers=4)\n",
    "dataloader_test = torch.utils.data.DataLoader(dataset_test, batch_size=16, shuffle=False, num_workers=4)\n",
    "dataloader_feeder = torch.utils.data.DataLoader(dataset_feeder, batch_size=16, shuffle=False, num_workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for taking a little look at the data :) \n",
    "# inputs, classes = next(iter(dataloader_train))\n",
    "# out = torchvision.utils.make_grid(inputs)\n",
    "# imshow(out, title=[class_labels[x] for x in classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting a subset to be able to test our code before doing big boi training\n",
    "subset1 = torch.utils.data.Subset(dataset_train, np.random.choice(len(dataset_train), 16, replace=False))\n",
    "subset2 = torch.utils.data.Subset(dataset_val, [1,8,9,16, 60, 80, 98, 100, 103, 20,31, 40,50,70,90,88])\n",
    "dataloader_tiny = DataLoader(subset1, batch_size=16, shuffle=True, num_workers=0)\n",
    "dataloader_tiny_val = DataLoader(subset2, batch_size=16, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing ResNet50 model \n",
    "and getting it ready for transfer learning!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put the pedal to the metal and use GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_prep_vgg16():\n",
    "    model = torchvision.models.vgg16(weights=models.VGG16_Weights.DEFAULT)\n",
    "    model.classifier[-1] = torch.nn.Linear(in_features=4096, out_features=7)\n",
    "\n",
    "    #Freeze layers\n",
    "    for param in model.features.parameters():\n",
    "      param.requires_grad = False\n",
    "\n",
    "    #Unfreeze classifier\n",
    "    for param in model.classifier.parameters():\n",
    "      param.requires_grad = True\n",
    "\n",
    "    model = model.to(device)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_weights = models.ResNet50_Weights.DEFAULT\n",
    "def load_and_prep_resnet50(weights = pretrained_weights):\n",
    "    model = torchvision.models.resnet50(weights=weights)\n",
    "    \n",
    "    #Replace last layer to match our 7 classes\n",
    "    model.fc = torch.nn.Linear(model.fc.in_features, 7)\n",
    "\n",
    "    # Freeze all layers (i.e., disable training so we dont start from scratch)\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    # Unfreeze final layer (named fc) s.t. we only train that to get a better starting point for fine tuning\n",
    "    for param in model.fc.parameters():\n",
    "        param.requires_grad = True\n",
    "    \n",
    "    # Put the model on the GPU\n",
    "    model = model.to(device)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def unfreeze_layers(model):\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "def unfreeze_layer4(model: torchvision.models.resnet50):\n",
    "    for param in model.layer4.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "def unfreeze_layer3(model: torchvision.models.resnet50):\n",
    "    for param in model.layer3.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "def model_frozen_status(model):\n",
    "    # Print layer freezing status\n",
    "    for name, param in model.named_parameters():\n",
    "        print(f\"{name} requires_grad={param.requires_grad}\")\n",
    "\n",
    "def get_optimizer(model):\n",
    "    #Use stochastic gradient descent and optimize parameters\n",
    "    return torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, optimizer, num_epoch=5, train = dataloader_train, validation= dataloader_validation):\n",
    "    acc_train = []\n",
    "    loss_train = []\n",
    "    acc_validation = []\n",
    "    loss_validation = []\n",
    "    best_acc = 0.0\n",
    "    best_loss = 1.0\n",
    "    best_epoch = 0\n",
    "    best_model_weight = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    since = time.time()\n",
    "    for epoch in range(num_epoch):\n",
    "        epoch_since = time.time()\n",
    "        print('Epoch {}/{}'.format(epoch+1, num_epoch))\n",
    "        print(\"-\"*10)\n",
    "        #training phase\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "        for inputs, labels in train:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            #zero the parameter gradients \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            #forward\n",
    "            with torch.set_grad_enabled(True):\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                criterion = torch.nn.CrossEntropyLoss()\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "        epoch_loss_train = running_loss / dataset_size_train\n",
    "        epoch_acc_train = running_corrects.double() / dataset_size_train\n",
    "        acc_train.append(epoch_acc_train.item())\n",
    "        loss_train.append(epoch_loss_train)\n",
    "        print('Train Loss: {:.4f} Acc: {:.4f}'.format(epoch_loss_train, epoch_acc_train))\n",
    "\n",
    "        #validation phase\n",
    "        model.eval()\n",
    "        running_loss_val = 0.0\n",
    "        running_corrects_val = 0\n",
    "        for inputs, labels in validation:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            with torch.set_grad_enabled(False):\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                criterion = torch.nn.CrossEntropyLoss()\n",
    "                loss = criterion(outputs, labels)\n",
    "            running_loss_val += loss.item() * inputs.size(0)\n",
    "            running_corrects_val += torch.sum(preds == labels.data)\n",
    "        epoch_loss_val = running_loss_val / dataset_size_val\n",
    "        epoch_acc_val = running_corrects_val.double() / dataset_size_val\n",
    "        acc_validation.append(epoch_acc_val.item())\n",
    "        loss_validation.append(epoch_loss_val)\n",
    "        print('Val Loss: {:.4f} Acc: {:.4f}'.format(epoch_loss_val, epoch_acc_val))\n",
    "        \n",
    "        if(epoch_acc_val >= best_acc):\n",
    "            if(epoch_loss_val < best_loss):\n",
    "                best_acc = epoch_acc_val\n",
    "                best_loss = epoch_loss_val \n",
    "                best_epoch = epoch+1\n",
    "                best_model_weight = copy.deepcopy(model.state_dict())\n",
    "        \n",
    "        time_epoch_val = time.time() - epoch_since           \n",
    "        print('Epoch time {:.0f}m {:.0f}s'.format(time_epoch_val // 60, time_epoch_val % 60))\n",
    "        print(\"-\"*10)\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print(\"Validation accuracies:\")\n",
    "    print(acc_validation)\n",
    "    print(\"Training accuracies:\")\n",
    "    print(acc_train)\n",
    "    print(\"Best model had accuracy {:.4f}, loss {:.4f} at epoch {}\".format(best_acc, best_loss, best_epoch))\n",
    "    data = {\"train_loss\": loss_train, \"val_loss\": loss_validation, \"train_acc\": acc_train, \"val_acc\": acc_validation, \"epochs\": num_epoch, \"batch_size\": train.batch_size}\n",
    "    model.load_state_dict(best_model_weight)\n",
    "    return model, data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labels_and_predictions(dataloader: DataLoader, model: models.ResNet, device) -> tuple[list[float], list[float]]:\n",
    "    '''\n",
    "    Gets all labels and predictions for the images in the dataloader \n",
    "    '''\n",
    "    predlist=torch.zeros(0,dtype=torch.long, device='cpu')\n",
    "    lbllist=torch.zeros(0,dtype=torch.long, device='cpu')\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, classes) in enumerate(dataloader):\n",
    "            inputs = inputs.to(device)\n",
    "            classes = classes.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            # Append batch prediction results\n",
    "            predlist=torch.cat([predlist,preds.view(-1).cpu()])\n",
    "            lbllist=torch.cat([lbllist,classes.view(-1).cpu()])\n",
    "    return lbllist.numpy(), predlist.numpy()\n",
    "\n",
    "def top_k_accuracy(dataloader: DataLoader, model: models.ResNet, device, k):\n",
    "    '''\n",
    "    Gets top k accurracy for the images in the dataloader \n",
    "    '''\n",
    "    lbllist=torch.zeros(0,dtype=torch.long, device='cpu')\n",
    "    outlits = torch.zeros(0, device='cpu')\n",
    "    total_pred =0 \n",
    "    correct_pred = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, classes) in enumerate(dataloader):\n",
    "            inputs = inputs.to(device)\n",
    "            classes = classes.to(device)\n",
    "            outputs = model(inputs)\n",
    "            # ee = sklearn.metrics.top_k_accuracy_score(classes, outputs, k=3)\n",
    "            _, preds = torch.topk(outputs, k)\n",
    "\n",
    "            for lab, cls in zip(classes, preds.detach().cpu()):\n",
    "                if lab in cls:\n",
    "                    correct_pred += 1\n",
    "                total_pred +=1            \n",
    "    return correct_pred / total_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_stats(data: dict, print_arrays=False):\n",
    "    if print_arrays:\n",
    "        print(\"Training accuracies\")\n",
    "        print(data[\"train_acc\"])\n",
    "        print(\"Validation Accuracies\")\n",
    "        print(data[\"val_acc\"])\n",
    "        print(\"Validation Loss\")\n",
    "        print(data[\"val_loss\"])\n",
    "    print(\"Lowest loss was {:.4f} at epoch {}\".format(np.min(data[\"val_loss\"]), np.argmin(data[\"val_loss\"])+1))\n",
    "    print(\"Highest accuracy was {:.4f} at epoch {}\".format(np.max(data[\"val_acc\"]),np.argmax(data[\"val_acc\"])+1))\n",
    "    if (\"epochs\" in data):\n",
    "        print(\"Number of epochs run \", data[\"epochs\"])\n",
    "    if(\"batch_size\" in data):\n",
    "        print(\"Batch size was \", data[\"batch_size\"])\n",
    "    if(\"optimizer\" in data):\n",
    "        print(\"Optimizer used: \", data[\"optimizer\"])\n",
    "    if(\"test_acc\" in data):\n",
    "        print(\"Overall accuracy on test data {:.4f}\".format(data[\"test_acc\"]))\n",
    "    if(\"feeder_acc\" in data):\n",
    "        print(\"Overall accuracy on feeder data {:.4f}\".format(data[\"feeder_acc\"]))\n",
    "    if(\"feed_acc\" in data):\n",
    "        print(\"Overall accuracy on feeder data {:.4f}\".format(data[\"feed_acc\"]))\n",
    "    if(\"note\" in data):\n",
    "        print(data[\"note\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_function(model_path: str, model_key: str = \"model\", info_key: str = \"info\", device=device):\n",
    "    ''' \n",
    "    e.g. model, info = load_function(\"Cycle.tar\", model_key=\"model_cycle\", info_key = \"model_cycle_data\")  \n",
    "    or model, info = load_function(\"Cycle.tar\") if saved under model and info '''\n",
    "    loaded_info = torch.load(model_path, weights_only=False, map_location=device)\n",
    "    new_model = load_and_prep_resnet50()\n",
    "    new_model.load_state_dict(loaded_info[model_key])\n",
    "    info = loaded_info[info_key]\n",
    "    return new_model, info \n",
    "\n",
    "def save_function(model_path, model, info, extra_info):\n",
    "    ''' e.g. save_function(\"model_aug.tar\", model, info, extra={\"optimizer\": \"Adam\", \"test_acc\" 0.97, \"feeder_acc\": 0.38})'''\n",
    "    all_info = {}\n",
    "    all_info.update(info)\n",
    "    all_info.update(extra_info)\n",
    "    torch.save({\"model\": model.state_dict(), \"info\": all_info}, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(truel, predl):\n",
    "    return np.sum(predl==truel)/predl.size * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the transforms including augmentations (and also the basic ToTensor and normalisation)\n",
    "preprocess_with_augmentation1 = transforms.Compose([\n",
    "    transforms.RandomRotation(degrees=10),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomResizedCrop(size=224,scale=(0.3,1)), # lowerbound the scale at 30 % of og img to not get too small portions\n",
    "    \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Datasets and loaders with augmentations added \n",
    "dataset_train_aug1 = datasets.ImageFolder(PATH_TRAIN, preprocess_with_augmentation1)\n",
    "dataloader_train_aug1 = torch.utils.data.DataLoader(dataset_train_aug1, batch_size=16, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the transforms including augmentations (and also the basic ToTensor and normalisation)\n",
    "preprocess_with_augmentation2 = transforms.Compose([\n",
    "    transforms.ColorJitter(brightness=0.1), # Added\n",
    "    transforms.GaussianBlur(kernel_size=(5,5), sigma=(7, 9)), # Added\n",
    "    transforms.RandomRotation(degrees=10),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomResizedCrop(size=224,scale=(0.3,1)), # lowerbound the scale at 30 % of og img to not get too small portions\n",
    "    \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Datasets and loaders with augmentations added \n",
    "dataset_train_aug2 = datasets.ImageFolder(PATH_TRAIN, preprocess_with_augmentation2)\n",
    "dataloader_train_aug2 = torch.utils.data.DataLoader(dataset_train_aug2, batch_size=16, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the transforms including augmentations (and also the basic ToTensor and normalisation)\n",
    "preprocess_with_augmentation3 = transforms.Compose([\n",
    "    transforms.GaussianBlur(kernel_size=(5,5), sigma=(7, 9)), # Added\n",
    "    transforms.RandomRotation(degrees=10),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomResizedCrop(size=224,scale=(0.3,1)), # lowerbound the scale at 30 % of og img to not get too small portions\n",
    "\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Datasets and loaders with augmentations added \n",
    "dataset_train_aug3 = datasets.ImageFolder(PATH_TRAIN, preprocess_with_augmentation3)\n",
    "dataloader_train_aug3 = torch.utils.data.DataLoader(dataset_train_aug3, batch_size=16, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(true_labels, pred_labels, class_labels, normalize=False, verbose=False):\n",
    "    \"\"\"\n",
    "    Computes and plots the confusion matrix of given model on provided data (as a dataloader). \n",
    "    May be set to normalize.\n",
    "    \"\"\"\n",
    "    # compute confusion matrix\n",
    "\n",
    "    cm = confusion_matrix(true_labels, pred_labels)\n",
    "    print(cm)\n",
    "    if normalize: cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    # start plotting\n",
    "    fig, ax = plt.subplots(figsize=(8,8))\n",
    "    im = ax.imshow(cm, cmap=plt.cm.Greens,vmin=0, vmax=1)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # display and label all ticks, set titles\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           xticklabels=class_labels, yticklabels=class_labels,\n",
    "           title=\"Normalized confusion matrix\" if normalize else \"Confusion matrix\", \n",
    "           ylabel=\"True label\",\n",
    "           xlabel=\"Predicted label\"\n",
    "           )\n",
    "    \n",
    "    # rotate labels\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "    \n",
    "    # Add annotations in each cell\n",
    "    fmt = '.2f' if normalize else 'd' # format based on normalize setting\n",
    "    thresh = cm.max() / 2. # when to switch from black to white text\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    return ax\n",
    "\n",
    "def plot_accuracies(train_accs, test_accs, legends=[\"Train\", \"Val\"]):\n",
    "    num_epochs = len(train_accs)\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.plot(np.arange(1,num_epochs+1), train_accs,'-')\n",
    "    plt.plot(np.arange(1,num_epochs+1), test_accs,'-')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend(legends)\n",
    "    plt.title('Accuracy/Epoch')\n",
    "    plt.show()\n",
    "\n",
    "def plot_loss(train_loss, val_loss, legends=[\"Train\", \"Val\"]):\n",
    "    num_epochs = len(train_loss)\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.plot(np.arange(1,num_epochs+1), train_loss,'-')\n",
    "    plt.plot(np.arange(1,num_epochs+1), val_loss,'-')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend(legends)\n",
    "    plt.title('Loss/Epoch')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
